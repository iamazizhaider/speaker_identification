{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from spafe.features.rplp import plp\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_files = [\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ahmed_Armaghan\\\\SP80644_M_SNG_L56.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ahmed_Armaghan\\\\SP80644_M_SNG_L70.tdf',     \n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L55.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L70.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L57.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L65.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L66.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L18.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L55.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L70.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L56.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L51.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L54.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L70.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L51.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L55.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L55.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L70.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L51.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L54.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L70.tdf',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L6.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L67.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L69.tdf'\n",
    "]\n",
    "\n",
    "audio_files = [\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ahmed_Armaghan\\\\SP80644_M_SNG_L56.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ahmed_Armaghan\\\\SP80644_M_SNG_L70.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L55.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L70.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L57.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L65.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L66.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L18.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L55.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L70.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L56.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L51.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L54.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L70.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L51.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L55.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L55.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L70.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L51.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L54.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L70.wav',\n",
    "'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L6.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L67.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L69.wav'\n",
    "]\n",
    "\n",
    "total_time = 0\n",
    "data_details = {}\n",
    "\n",
    "for i in range(len(tdf_files)):\n",
    "    with open(tdf_files[i], 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    speaker_data = 0\n",
    "    for line in lines[3:]:  # Skip the first three lines\n",
    "        data = line.strip().split('\\t')\n",
    "        audio_file, channel, start, end, speaker, speakerType, speakerDialect, _, _, segment, _ = data\n",
    "        segment = float(end) - float(start)\n",
    "        if segment < 3:\n",
    "            continue\n",
    "        speaker_data += segment\n",
    "    if speaker not in data_details:\n",
    "        data_details[speaker] = round(speaker_data/60, 2)  # Initialize time for new speaker\n",
    "    else:\n",
    "        data_details[speaker] += round(speaker_data/60, 2)  # Update speaker's total time\n",
    "    total_time += speaker_data\n",
    "\n",
    "print('Total Time Available for Processing is ' + str(round(total_time/60, 2)) + ' minutes')\n",
    "print('Individual Details of Speaker')\n",
    "print(data_details)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFCC features and labels from numpy files\n",
    "MFCC = np.load('MFCC_features.npy')\n",
    "PLP = np.load('PLP_features.npy')\n",
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_r = 8000;      # Set sample rate as 8kHz\n",
    "classes = {\"ali\":1,\"ayesha\":2,\"mahnoor\":3,\"maryam\":4,\"usman_amin\":5,\"askari\":6,\"usman_hassan\":7,\"huzaifa\":8}\n",
    "\n",
    "\n",
    "tdf_files = [\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L55.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L70.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L57.tdf',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L65.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L66.tdf',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L55.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L70.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L56.tdf',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L54.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L70.tdf',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L51.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L55.tdf',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L55.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L70.tdf',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L51.tdf', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L54.tdf', \n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L6.tdf'#, 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L67.tdf'\n",
    "            ]\n",
    "\n",
    "audio_files = [\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L55.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L70.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ali_Hussain\\\\SP80643_M_SNG_L57.wav',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L65.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Ayesha_Farooq\\\\SP80538_F_SNG_L66.wav',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L55.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L70.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Mahnoor_Khalique\\\\SP80645_F_SNG_L56.wav',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L54.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Maryam_Zahra\\\\SP80640_F_SNG_L70.wav',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L51.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Usman_Amin\\\\SP80540_M_SNG_L55.wav',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L55.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Askari_Zaidi\\\\SP80641_M_SNG_L70.wav',\n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L51.wav', 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\Data\\\\Usman_Hassan\\\\SP80642_M_SNG_L54.wav', \n",
    "    'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L6.wav'#, 'C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\Data\\\\Muhammad_Huzaifa\\\\SP80539_M_SNG_L67.wav'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC = []          # empty list to store extracted MFCC features of data\n",
    "PLP = []           # empty list to store extracted PLP features of data\n",
    "labels = []        # empty list to store labels of data\n",
    "\n",
    "for i in range(len(tdf_files)):\n",
    "    with open(tdf_files[i], 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines[3:]:  # Skip the first three lines\n",
    "        data = line.strip().split('\\t')\n",
    "        audio_file, channel, start, end, speaker, speakerType, speakerDialect, _, _, segment, _ = data\n",
    "\n",
    "        if (float(end) - float(start)) < 3:\n",
    "            continue\n",
    "\n",
    "        s = int(float(start) * sam_r)  # convert start time to samples\n",
    "        e = int(float(end) * sam_r)  # convert end time to samples\n",
    "\n",
    "        if not os.path.exists(audio_files[i]):\n",
    "            print(f\"Audio file not found: {audio_files[i]}\")\n",
    "            continue\n",
    "        \n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(audio_files[i], sr=sam_r)\n",
    "        audio_segment = audio[s:e]\n",
    "\n",
    "        # extract 5 MFCC coefficients from the selected audio segment and take transpose and then compute the mean\n",
    "        mfcc_features = np.mean(librosa.feature.mfcc(y=audio_segment, sr=sam_r, n_mfcc=5).T, axis=0)\n",
    "        MFCC.append(mfcc_features)         \n",
    "\n",
    "        # extract 13 cepsrtal features from the selected audio segment then compute the mean\n",
    "        plp_features = np.mean(plp(audio_segment, sam_r, 13), axis=0)\n",
    "        PLP.append(plp_features)  \n",
    "\n",
    "        # extract the speaker name as the label against the data entry\n",
    "        speaker = classes[speaker]\n",
    "        labels.append(speaker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MFCC and PLP features and labels to numpy files\n",
    "np.save('C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\MFCC_features.npy', MFCC)\n",
    "np.save('C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\PLP_features.npy', PLP)\n",
    "np.save('C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% Training Data and 20% Test Data\n",
    "# Splitting the data into training and test sets\n",
    "X_train_mfcc, X_test_mfcc, y_train_mfcc, y_test_mfcc = train_test_split(MFCC, labels, test_size=0.2)\n",
    "X_train_plp, X_test_plp, y_train_plp, y_test_plp = train_test_split(PLP, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GMM-UBM classifier\n",
    "clf_gmm_mfcc = GaussianMixture(n_components=8, covariance_type='full', max_iter=500).fit(X_train_mfcc)\n",
    "\n",
    "# Unsupervised Learning \n",
    "# Predict labels for the test set\n",
    "y_pred_mfcc = clf_gmm_mfcc.predict(X_test_mfcc)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test_mfcc, y_pred_mfcc)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],          # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],     # Kernel type\n",
    "    'gamma': ['scale', 'auto']       # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Create the SVM model\n",
    "svm_model_mfcc = svm.SVC()\n",
    "\n",
    "# Perform grid search using cross-validation\n",
    "grid_search = GridSearchCV(svm_model_mfcc, param_grid, cv=5)\n",
    "grid_search.fit(X_train_mfcc, y_train_mfcc)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with best hyperparameters on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_mfcc, y_test_mfcc)\n",
    "print(\"Accuracy with Best Hyperparameters:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.14239482200647\n"
     ]
    }
   ],
   "source": [
    "clf_svm_mfcc = svm.SVC(C=10, kernel='linear', gamma='scale').fit(X_train_mfcc, y_train_mfcc)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_mfcc = clf_svm_mfcc.predict(X_test_mfcc)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test_mfcc, y_pred_mfcc)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GMM-UBM classifier\n",
    "clf_gmm_plp = GaussianMixture(n_components=8, covariance_type='full', max_iter=2000).fit(X_train_plp)\n",
    "\n",
    "# Unsupervised Learning \n",
    "# Predict labels for the test set\n",
    "y_pred_plp = clf_gmm_plp.predict(X_test_plp)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test_plp, y_pred_plp)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm_plp = svm.SVC(C=100, kernel='linear', gamma='scale').fit(X_train_plp, y_train_plp)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred_plp = clf_svm_plp.predict(X_test_plp)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test_plp, y_pred_plp)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording has been started. Start Speaking in the mic...\n",
      "Recording stopped. Processing on the Input Audio\n",
      "The predicted label is usman_amin\n",
      "Failed to Identify\n"
     ]
    }
   ],
   "source": [
    "duration = 5  # Duration for recording in seconds\n",
    "\n",
    "# Define the threshold for speaker identification\n",
    "threshold = 0.6\n",
    "\n",
    "# Load the dictionary mapping class labels to speaker identities\n",
    "classes = {\"ali\":1,\"ayesha\":2,\"mahnoor\":3,\"maryam\":4,\"usman_amin\":5,\"askari\":6,\"usman_hassan\":7,\"huzaifa\":8}\n",
    "\n",
    "testing_svm = svm.SVC(C=100, kernel='linear', gamma='scale').fit(MFCC, labels)\n",
    "\n",
    "# Function to extract MFCC features from audio\n",
    "def get_key(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def extract_mfcc(audio, sam_r):\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio.flatten(), sr=sam_r, n_mfcc=5).T, axis = 0)\n",
    "    mfcc_features = mfccs.reshape(1,-1)\n",
    "    return mfcc_features\n",
    "\n",
    "# Function to identify the speaker from MFCC features\n",
    "def identify_speaker(features):\n",
    "    predicted_label = testing_svm.predict(features)[0]\n",
    "\n",
    "    print('The predicted label is ' + get_key(classes,predicted_label))\n",
    "    \n",
    "    confidence = np.max(testing_svm.decision_function(features))\n",
    "    \n",
    "    if confidence > threshold:\n",
    "        speaker = get_key(classes,predicted_label)\n",
    "    else:\n",
    "        speaker = \"Unknown\"\n",
    "    \n",
    "    return speaker\n",
    "\n",
    "# Record audio in real-time and perform speaker identification\n",
    "def real_time_speaker_identification():\n",
    "\n",
    "    true_speaker = input('Enter the id of the speaker to be identified: ')\n",
    "\n",
    "    # Open an audio stream for recording\n",
    "    stream = sd.InputStream(samplerate=sam_r, channels=1)\n",
    "\n",
    "    print(\"Recording has been started. Start Speaking in the mic...\")\n",
    "    stream.start()\n",
    "    audio_frames = []\n",
    "\n",
    "    # Record audio for the specified duration\n",
    "    for _ in range(int(duration * sam_r)):\n",
    "        audio_frames.append(stream.read(1)[0])\n",
    "\n",
    "    # Stop the audio stream\n",
    "    stream.stop()\n",
    "    stream.close()\n",
    "\n",
    "    print(\"Recording stopped. Processing on the Input Audio\")\n",
    "\n",
    "    # Convert the audio frames to a numpy array\n",
    "    audio = np.array(audio_frames)\n",
    "\n",
    "    # Save the recorded audio to a WAV file (optional)\n",
    "    write(\"C:\\\\Users\\\\ApriZon\\\\Desktop\\\\CEP\\\\recorded_audio.wav\", sam_r, audio)\n",
    "\n",
    "    # Extract MFCC features from the recorded audio\n",
    "    mfcc_features = extract_mfcc(audio, sam_r)\n",
    "\n",
    "    # Identify the speaker from the MFCC features\n",
    "    speaker = identify_speaker(mfcc_features)\n",
    "\n",
    "    if speaker == true_speaker:\n",
    "        print('System has successfully recognized the speaker from the database')\n",
    "    else:\n",
    "        print('Failed to Identify')\n",
    "\n",
    "# Run the real-time speaker identification\n",
    "real_time_speaker_identification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
